{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import de la table des SARL - Unité légale\n",
    "data = pd.read_csv('C:/Users/Square 769/Documents/SIRENE/072019/BASE_FINALE_010819.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse et Exploration de données avec Pandas profiling\n",
    "import pandas_profiling as pp\n",
    "pp.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation variables descriptives SIRENE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'SECTION_NAF', hue = 'etatAdministratifUniteLegale', data = data)\n",
    "plt.xlabel(\"Secteur WebStat\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Effectifs Unité légale par secteur WebStat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['anc_der_chg_den'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Age de l'entreprise\n",
    "new_sarl = data.reset_index()\n",
    "test_den = pd.cut(new_sarl.age_unite_legale, [-1,6,11,20,999], labels = ['1-<6ans','2-<11ans','3-<20ans','4->20ans'])\n",
    "#test_den = np.where(test_den.isna(),'missing',test_den)\n",
    "\n",
    "new_sarl = new_sarl.join(test_den, rsuffix='_mod')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x = 'age_unite_legale_mod', hue = 'etatAdministratifUniteLegale', data = new_sarl)\n",
    "plt.xlabel(\"Tranches age UL\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Effectifs Unité légale par tranches d'Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Ancienneté depuis le dernier changement de catégorie juridique\n",
    "new_sarl = data.reset_index()\n",
    "test_den = pd.cut(new_sarl.anc_der_chg_cat_ju, [-10,11,22,30,999], labels = ['1-<11ans','2-<22ans','3-<30ans','4->30ans'])\n",
    "\n",
    "new_sarl = new_sarl.join(test_den, rsuffix='_mod')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x = 'anc_der_chg_cat_ju_mod', hue = 'etatAdministratifUniteLegale', data = new_sarl)\n",
    "plt.xlabel(\"Tranches ancienneté\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Effectifs Unité légale par ancienneté depuis le dernier changement de catégorie juridique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Ancienneté depuis le dernier changement d'activité principale\n",
    "new_sarl = data.reset_index()\n",
    "test_den = pd.cut(new_sarl.anc_der_chg_act, [-10,6,10,15,999], labels = ['1-<6ans','2-<10ans','3-<15ans','4->15ans'])\n",
    "\n",
    "new_sarl = new_sarl.join(test_den, rsuffix='_mod')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x = 'anc_der_chg_act_mod', hue = 'etatAdministratifUniteLegale', data = new_sarl)\n",
    "plt.xlabel(\"Tranches ancienneté\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Effectifs Unité légale par ancienneté depuis le dernier changement d'activité principale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Ancienneté depuis le dernier changement de caractère employeur de l'unité légale\n",
    "new_sarl = data.reset_index()\n",
    "test_den = pd.cut(new_sarl.anc_der_chg_emp, [-10,3,7,13,999], labels = ['1-<3ans','2-<7ans','3-<13ans','4->13ans'])\n",
    "\n",
    "new_sarl = new_sarl.join(test_den, rsuffix='_mod')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x = 'anc_der_chg_emp_mod', hue = 'etatAdministratifUniteLegale', data = new_sarl)\n",
    "plt.xlabel(\"Tranches ancienneté\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Effectifs Unité légale par ancienneté depuis le dernier changement de caractère employeur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Ancienneté depuis le dernier changement de caractère employeur de l'unité légale\n",
    "new_sarl = data.reset_index()\n",
    "test_den = pd.cut(new_sarl.anc_der_chg_den, [-10,12,22,27,999], labels = ['1-<12ans','2-<22ans','3-<27ans','4->27ans'])\n",
    "\n",
    "new_sarl = new_sarl.join(test_den, rsuffix='_mod')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x = 'anc_der_chg_den_mod', hue = 'etatAdministratifUniteLegale', data = new_sarl)\n",
    "plt.xlabel(\"Tranches ancienneté\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Effectifs Unité légale par ancienneté depuis le dernier changement de dénomination légale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables exclues short-list variables financières\n",
    "out_lst = ['N0_AE','VarN0_AF','VarN0_BE','N0_BV',\n",
    "            'VarN0_CB','N0_CE','VarN0_CE','N0_CI',\n",
    "            'VarN0_CI','N0_CL','VarN0_CL','N0_CP',\n",
    "            'N0_DE','VarN0_DE','N0_FO','VarN0_FO',\n",
    "            'VarN0_IN','VarN0_IR','N0_NC','VarN0_NC',\n",
    "            'N0_PK','N0_PP','VarN0_PP','VarN0_PT',\n",
    "            'N0_RB','N0_RF','N0_RN','VarN0_RN',\n",
    "            'N0_RP','VarN0_RP','N0_ST','VarN0_ST','N0_TM',\n",
    "            'nicSiegeUniteLegale','dateDebut','siren',\n",
    "            'caractereEmployeurUniteLegale','economieSocialeSolidaireUniteLegale']\n",
    "data.drop(data[out_lst], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export nombre de manquant par feature\n",
    "output = pd.DataFrame(pd.isnull(data).sum(), columns=['VAR'])\n",
    "output.to_csv('C:/Users/Square 769/Documents/SIRENE/072019/MISSING.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short list feature après première sélection\n",
    "short_list = ['etatAdministratifUniteLegale','N0_AF','N0_BE','N0_BV','N0_CB','N0_DE','N0_IR','N0_PK','N0_PT',\n",
    "              'VarN0_AF','VarN0_BV','VarN0_CP','VarN0_PK','VarN0_TM','VarN0_RN','VarN0_RB','nb_etablissement_ferme',\n",
    "              'VAR_DEFAILLANCE','anc_der_chg_cat_ju','anc_der_chg_act','anc_der_chg_den','anc_der_chg_emp','age_unite_legale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application des découpages optimisés\n",
    "N0_AF = pd.cut(data.N0_AF, [-1000,125.8,204.7], labels = ['<125,8','<204,7'])\n",
    "N0_BE = pd.cut(data.N0_BE, [-1000,35.7,74.9], labels = ['<35,7','<74,9'])\n",
    "N0_BV = pd.cut(data.N0_BV, [-1000,44.7,574.8], labels = ['<44,7','<574,8'])\n",
    "N0_CB = pd.cut(data.N0_CB, [-1000,20.9,28.7], labels = ['<20,9','<28,7'])\n",
    "N0_DE = pd.cut(data.N0_DE, [-1000,58.3,182.6], labels = ['<58,3','<182,6'])\n",
    "N0_IR = pd.cut(data.N0_IR, [-1000,11.6,37.1], labels = ['<11,6','<37,1'])\n",
    "N0_PK = pd.cut(data.N0_PK, [-1000,54.2,120.1], labels = ['<54,2','<120,1'])\n",
    "N0_PT = pd.cut(data.N0_PT, [-1000,67.3,194.4], labels = ['<67,3','<194,4'])\n",
    "\n",
    "VarN0_AF = pd.cut(data.VarN0_AF, [-1000,0.3455,1.1658], labels = ['d<0,35','d<1,17'])\n",
    "VarN0_BV = pd.cut(data.VarN0_BV, [-1000,-0.0022,0.4762], labels = ['d<0','d<0,48'])\n",
    "VarN0_CP = pd.cut(data.VarN0_CP, [-1000,-0.0182,0.1798], labels = ['d<-0,02','d<0,18'])\n",
    "VarN0_PK = pd.cut(data.VarN0_PK, [-1000,-0.0116,0.3569], labels = ['d<-0,01','d<0,36'])\n",
    "VarN0_TM = pd.cut(data.VarN0_TM, [-1000,0.0051,0.3209], labels = ['d<0,01','d<0,32'])\n",
    "VarN0_RN = pd.cut(data.VarN0_RN, [-1000,0,0.7838], labels = ['d<0','d<0,78'])\n",
    "VarN0_RB = pd.cut(data.VarN0_RB, [-1000,-0.0094,0.4211], labels = ['d<-0,01','d<0,42'])\n",
    "\n",
    "VAR_DEFAILLANCE = pd.cut(data.VAR_DEFAILLANCE, [-1000,0.1542,0.6022], labels = ['d<0,15','d<0,6'])\n",
    "NB_ETABLISSEMENT_FERME = pd.cut(data.nb_etablissement_ferme, [-1000,0,1000], labels = ['<1','>1'])\n",
    "\n",
    "JU = pd.cut(data.anc_der_chg_cat_ju, [-1000,11.0,16.0,20.0,118.0], labels = ['<11','<16','<20','<118'])\n",
    "ACT = pd.cut(data.anc_der_chg_act, [-1000,4.0,9.0,21.0,118.0], labels = ['<4','<9','<21','<118'])\n",
    "DEN = pd.cut(data.anc_der_chg_den, [-1000,9.0,16.0,23.0,118.0], labels = ['<9','<16','<23','<118'])\n",
    "EMP = pd.cut(data.anc_der_chg_emp, [-1000,3.0,6.0,21.0,114.0], labels = ['3<','<6','<21','<114'])\n",
    "AGE = pd.cut(data.age_unite_legale, [-1000,3.0,7.0,10.0,118.0], labels = ['<3','<7','<10','<118'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0_AF = np.where(N0_AF.isna(), 'missing', N0_AF)\n",
    "N0_BE = np.where(N0_BE.isna(), 'missing', N0_BE)\n",
    "N0_BV = np.where(N0_BV.isna(), 'missing', N0_BV)\n",
    "N0_CB = np.where(N0_CB.isna(), 'missing', N0_CB)\n",
    "N0_DE = np.where(N0_DE.isna(), 'missing', N0_DE)\n",
    "N0_IR = np.where(N0_IR.isna(), 'missing', N0_IR)\n",
    "N0_PK = np.where(N0_PK.isna(), 'missing', N0_PK)\n",
    "N0_PT = np.where(N0_PT.isna(), 'missing', N0_PT)\n",
    "\n",
    "VarN0_AF = np.where(VarN0_AF.isna(), 'missing', VarN0_AF)\n",
    "VarN0_BV = np.where(VarN0_BV.isna(), 'missing', VarN0_BV)\n",
    "VarN0_CP = np.where(VarN0_CP.isna(), 'missing', VarN0_CP)\n",
    "VarN0_PK = np.where(VarN0_PK.isna(), 'missing', VarN0_PK)\n",
    "VarN0_TM = np.where(VarN0_TM.isna(), 'missing', VarN0_TM)\n",
    "VarN0_RN = np.where(VarN0_RN.isna(), 'missing', VarN0_RN)\n",
    "VarN0_RB = np.where(VarN0_RB.isna(), 'missing', VarN0_RB)\n",
    "\n",
    "DEF = np.where(VAR_DEFAILLANCE.isna(), 'missing', VAR_DEFAILLANCE)\n",
    "FER = np.where(NB_ETABLISSEMENT_FERME.isna(), 'missing', NB_ETABLISSEMENT_FERME)\n",
    "\n",
    "JU = np.where(JU.isna(), 'missing', JU)\n",
    "ACT = np.where(ACT.isna(), 'missing', ACT)\n",
    "DEN = np.where(DEN.isna(), 'missing', DEN)\n",
    "EMP = np.where(EMP.isna(), 'missing', EMP)\n",
    "AGE = np.where(AGE.isna(), 'missing', AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_db = pd.get_dummies(data.etatAdministratifUniteLegale, prefix = \"CESSATION\")\n",
    "expert_db.drop('CESSATION_A', axis = 1, inplace = True)\n",
    "\n",
    "expert_db = expert_db.join(pd.get_dummies(N0_BE, prefix = \"BE\"))\n",
    "expert_db = expert_db.join(pd.get_dummies(N0_PT, prefix = \"PT\"))\n",
    "expert_db = expert_db.join(pd.get_dummies(VarN0_CP, prefix = \"dCP\"))\n",
    "expert_db = expert_db.join(pd.get_dummies(VarN0_TM, prefix = \"dTM\"))\n",
    "expert_db = expert_db.join(pd.get_dummies(DEF, prefix = \"DEF\"))\n",
    "expert_db = expert_db.join(pd.get_dummies(ACT, prefix = \"ACT\"))\n",
    "expert_db = expert_db.join(pd.get_dummies(FER, prefix = \"FER\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "def cramers_corrected_stat(x,y):\n",
    "\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher, \n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    result=-1\n",
    " \n",
    "    conf_matrix=pd.crosstab(x, y)\n",
    "\n",
    "    if conf_matrix.shape[0]==2:\n",
    "        correct=False\n",
    "    else:\n",
    "        correct=True\n",
    "\n",
    "    chi2 = ss.chi2_contingency(conf_matrix, correction=correct)[0]\n",
    "\n",
    "    n = sum(conf_matrix.sum())\n",
    "    phi2 = chi2/n\n",
    "    r,k = conf_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    result=np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "    \n",
    "    return round(result, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vect = (N0_AF, N0_BE, N0_BV, N0_CB, N0_DE, N0_IR, N0_PK, N0_PT,\n",
    "             VarN0_AF, VarN0_BV, VarN0_CP, VarN0_PK, VarN0_TM, VarN0_RN, VarN0_RB,\n",
    "             DEF, JU, ACT, DEN, EMP, AGE, FER)\n",
    "\n",
    "#list_vect = (N0_CB, N0_PT, VarN0_BV, VarN0_RN, ACT, DEF, FER)\n",
    "\n",
    "#list_vect = (N0_BV, VarN0_BV, VarN0_CP, VarN0_TM, DEF, ACT, FER)\n",
    "list_vect = (N0_BE, N0_PT, VarN0_CP, VarN0_TM, DEF, ACT, FER)\n",
    "\n",
    "\n",
    "liste = []\n",
    "for i in list_vect:\n",
    "    for j in list_vect:\n",
    "        cram = cramers_corrected_stat(i,j)\n",
    "        liste.append(cram)\n",
    "    \n",
    "print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_v = (AF, BE, BV, CB, CP, IN, IR,\n",
    "            PK, PT, RB, TM, DEF, JU, ACT, DEN, EMP, AGE, FER)\n",
    "\n",
    "liste = []\n",
    "for i in list_v:\n",
    "    cram = cramers_corrected_stat(i,data.etatAdministratifUniteLegale)\n",
    "    liste.append(cram)\n",
    "    \n",
    "print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test des variables combinées mod N0 / N1\n",
    "liste = ('Mod_AE','Mod_AF','Mod_BE','Mod_BV','Mod_CB', \n",
    "        'Mod_CE','Mod_CI','Mod_CL','Mod_DE','Mod_FO', \n",
    "        'Mod_IR','Mod_NC','Mod_PK','Mod_PP','Mod_PT', \n",
    "        'Mod_RF','Mod_RN','Mod_RB', 'Mod_RP')\n",
    "\n",
    "for j in liste:\n",
    "    print(\"Feature ---- V-Cramer\")\n",
    "    print(j, \"----\", cramers_corrected_stat(data[j],data.etatAdministratifUniteLegale))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.countplot(x = j, hue = 'etatAdministratifUniteLegale', data = data)\n",
    "    plt.xlabel('Variable '+j)\n",
    "    plt.ylabel('Fréquence Actif/Cessation')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.countplot(x = 'Mod_CE', data = data)\n",
    "plt.xlabel('Variable Mod_CE')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = expert_db['CESSATION_C']\n",
    "feature = expert_db.iloc[:,1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size = 0.30, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(C = 1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_2 = clf.predict(X_train)\n",
    "print(\"Echantillon train\")\n",
    "print(cm(y_train, y_pred_2))\n",
    "print(\"Echantillon test\")\n",
    "print(cm(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[0,1]\n",
    "plt.figure(figsize=(8,6))\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "sns.heatmap(pd.DataFrame(cm(y_test, y_pred)), annot = True, cmap = 'Reds', fmt = 'g')\n",
    "plt.title('Confusion matrix', y = 1.1)\n",
    "plt.ylabel('Current label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AR on test sample :\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(clf.coef_, columns = X_train.columns).transpose()\n",
    "pd.DataFrame({\"Coefficients\" : clf.coef_[0]}, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred_2))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X_train, y_train, cv = 10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Predict\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cv_pred = cross_val_predict(clf, X_test, y_test, cv = 10)\n",
    "print(classification_report(y_test, cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV Accuracy Curve\n",
    "sco = pd.DataFrame(scores, columns=['CV Accuracy'])\n",
    "score_test = clf.score(X_test, y_test)\n",
    "plt.plot(sco.index, sco['CV Accuracy'], label='Logistic Regression Test Sample (AR = %0.4f)' % score_test)\n",
    "plt.ylim([0.923, 0.927])\n",
    "plt.plot([0, 10], [score_test, score_test],'r--')\n",
    "plt.xlabel('K Folds')\n",
    "plt.ylabel('Score')\n",
    "plt.title('K Folds cross-validation')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, clf.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
